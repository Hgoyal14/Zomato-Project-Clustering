{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member**     - Harshita Goyal"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this project is to build a complete machine learning system that can use data-driven methods to look at and group restaurants. The main goal of the project is to use machine learning algorithms that don't need any help to group restaurants that are similar based on their ratings, prices, popularity, cuisines, and other traits and customer preferences. This kind of segmentation can help businesses make smart choices about things like who to market to, how much to charge, and how to market.\n",
        "\n",
        "The first thing to do for the project is to gather and analyze data. This meant loading and looking through several datasets that had information about restaurants and reviews from customers. We did some initial exploratory data analysis (EDA) to learn how the data was set up, find missing values, duplicates, and outliers, and use charts and plots to show important connections. This step taught us about the spread of ratings, the cost patterns, the number of reviews, and what people like to eat.\n",
        "\n",
        "\n",
        "\n",
        "After that, the dataset was cleaned up and made ready for machine learning. We fixed data formats that weren't consistent, got rid of duplicate entries, and deal with missing values in the right way. We used feature engineering to make useful variables like cost categories, review counts that have been log-transformed, and indicators of value for money. We used one-hot encoding and label encoding to encode categorical variables. We also used feature scaling to make sure that all of the numerical features had the same effect on distance-based clustering.\n",
        "\n",
        "We used natural language processing (NLP) techniques because the dataset also had reviews from customers that were written down. Lowercasing, removing punctuation, URLs, numbers, stopwords, tokenization, lemmatization, part-of-speech tagging, and TF-IDF vectorization were all steps in the preprocessing of text. These steps turned unstructured review text into numbers that could be used to figure things out.\n",
        "\n",
        "Three distinct unsupervised machine learning models were executed and evaluated. We picked K-Means clustering as our first model because it's easy to use and can get bigger. We used the second model, DBSCAN, to find groups of points based on how close they are to each other and how much noise or outliers they have. The third model used to figure out how restaurants are connected was Agglomerative (Hierarchical) Clustering. We used the Silhouette Score to find out how well the model worked. This score tells you how well the data points are split up and grouped together.\n",
        "\n",
        "We set the hyperparameters for each model by using the Elbow Method for K-Means, epsilon tuning for DBSCAN, and linkage analysis for Agglomerative Clustering. We picked K-Means as the final model because it worked well, was easy to understand, and had a higher silhouette score. By looking at the cluster centroids, we were able to figure out which features were most important for dividing restaurants into groups.\n",
        "\n",
        "Finally, joblib was used to save the best model so it could be used again later. The saved model was reloaded and tested on new data to make sure it was correct. The project ends by talking about how putting restaurants together can help businesses, like by making it easier to find customers, plan ahead, and market to them. This project uses machine learning ideas in every step, from getting the data ready to using the model."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e0lhV0dqSayw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a lot of data about prices, customer ratings, reviews, and food preferences in the restaurant business. But it's hard to find meaningful patterns and customer groups by looking at this data by hand. The goal of this project is to put restaurants into meaningful groups based on their traits without using pre-defined labels. The goal of the project is to use unsupervised machine learning methods to find restaurants that are similar, find hidden patterns, and give insights that can help businesses make better decisions, like targeted marketing, pricing optimization, and strategies for getting customers to interact with them."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "resturant_df=pd.read_csv('Zomato Restaurant names and Metadata.csv')\n",
        "reviews_df=pd.read_csv('Zomato Restaurant reviews.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "resturant_df.head()\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df.head()"
      ],
      "metadata": {
        "id": "xfg-_SvaTNUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resturant_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df.shape"
      ],
      "metadata": {
        "id": "1KKcBSHWTYaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "resturant_df.info()\n",
        "reviews_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "resturant_df.duplicated().sum()\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "nCs9eibkWCvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "resturant_df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df.isnull().sum()"
      ],
      "metadata": {
        "id": "2LWxKtAiWY0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.heatmap(resturant_df.isnull(), cbar=False)\n",
        "plt.title(\"Missing Values Heatmap - Restaurant Dataset\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.heatmap(reviews_df.isnull(), cbar=False)\n",
        "plt.title(\"Missing Values Heatmap - Reviews Dataset\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project uses two datasets: one containing restaurant-level metadata and another containing customer review information.\n",
        "The restaurant dataset includes features such as restaurant name, cost, cuisines, collections, and timings, which are useful for clustering restaurants.\n",
        "The review dataset contains customer ratings, review text, reviewer details, and timestamps, which help in analyzing customer behavior and satisfaction.\n",
        "Most columns have very few missing values, except the Collections column, which has a higher number of missing entries.\n",
        "Overall, the dataset is suitable for exploratory data analysis and unsupervised machine learning after appropriate data cleaning and preprocessing."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "resturant_df.columns\n"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df.columns"
      ],
      "metadata": {
        "id": "7LIr-0V7eorp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "resturant_df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_df.describe()"
      ],
      "metadata": {
        "id": "XDcvkhzye-qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "Name: Name of the restaurant\n",
        "\n",
        "Links: Zomato URL of the restaurant\n",
        "\n",
        "Cost: Approximate cost for two people\n",
        "\n",
        "Collections: Zomato category or collection tags\n",
        "\n",
        "Cuisines: Types of cuisines served by the restaurant\n",
        "\n",
        "Timings: Opening and closing time of the restaurant\n",
        "\n",
        "Reviewer: Name of the reviewer\n",
        "\n",
        "Review: Textual feedback provided by the customer\n",
        "\n",
        "Rating: Rating given by the customer\n",
        "\n",
        "Time: Date and time when the review was posted"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for col in resturant_df.columns:\n",
        "    print(f\"{col}: {resturant_df[col].nunique()}\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in reviews_df.columns:\n",
        "    print(f\"{col}: {reviews_df[col].nunique()}\")"
      ],
      "metadata": {
        "id": "f_8JabZVfhon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "# Handling Missing Values\n",
        "resturant_df['Collections'] = resturant_df['Collections'].fillna('Not Specified')\n",
        "resturant_df['Timings'] = resturant_df['Timings'].fillna('Not Available')\n",
        "resturant_df['Cuisines'] = resturant_df['Cuisines'].fillna('Unknown')\n",
        "\n",
        "# Removing Duplicate Rows\n",
        "restaurant_df = resturant_df.drop_duplicates()\n",
        "\n",
        "#Cleaning Cost Column (if cost is stored as string)\n",
        "if restaurant_df['Cost'].dtype == 'object':\n",
        "    restaurant_df['Cost'] = restaurant_df['Cost'].str.replace(',', '')\n",
        "    restaurant_df['Cost'] = pd.to_numeric(restaurant_df['Cost'], errors='coerce')\n",
        "\n",
        "# Removing Duplicate Reviews\n",
        "review_df = reviews_df.drop_duplicates()\n",
        "\n",
        "# Handling Missing Values in Reviews\n",
        "review_df['Review'] = review_df['Review'].fillna('No Review')\n",
        "review_df['Rating'] = pd.to_numeric(review_df['Rating'], errors='coerce')\n",
        "\n",
        "# Dropping rows with missing ratings (important for analysis)\n",
        "review_df = review_df.dropna(subset=['Rating'])\n",
        "\n",
        "# Aggregating Review Data\n",
        "review_summary = review_df.groupby('Restaurant').agg({\n",
        "    'Rating': ['mean', 'count']\n",
        "}).reset_index()\n",
        "\n",
        "review_summary.columns = ['Restaurant', 'Avg_Rating', 'Total_Reviews']\n",
        "\n",
        "# Merging Restaurant and Review Data\n",
        "final_df = restaurant_df.merge(\n",
        "    review_summary,\n",
        "    left_on='Name',\n",
        "    right_on='Restaurant',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Filling missing aggregated review values\n",
        "final_df['Avg_Rating'] = final_df['Avg_Rating'].fillna(0)\n",
        "final_df['Total_Reviews'] = final_df['Total_Reviews'].fillna(0)\n",
        "\n",
        "# Display cleaned dataset\n",
        "final_df.head()\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing values were handled by filling them with appropriate labels, and duplicate records were removed to ensure clean data. The cost column was cleaned and converted into numerical form for analysis. Review data was processed by removing invalid entries and aggregating ratings and review counts for each restaurant. Finally, restaurant and review datasets were merged to create a single, analysis-ready dataset.\n",
        "\n",
        "From the analysis, it was observed that many restaurants are not part of any Zomato collection, cost data is mostly complete, and there is noticeable variation in restaurant ratings and popularity, which makes the data suitable for clustering."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.scatterplot(data=final_df, x='Cost', y='Avg_Rating')\n",
        "plt.title('Cost vs Average Rating of Restaurants')\n",
        "plt.xlabel('Cost for Two')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scatter plot was chosen because it is effective in understanding the relationship between two numerical variables. It helps visualize how restaurant cost is related to customer ratings and whether higher-priced restaurants tend to receive better ratings."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that higher cost does not always result in higher ratings. Many low and mid-priced restaurants receive good ratings, while some expensive restaurants have average ratings. This indicates that customer satisfaction is influenced by factors beyond just pricing."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insights can help create a positive business impact. Customers can identify good-quality restaurants without assuming that higher cost means better experience. For Zomato, this insight helps promote well-rated budget and mid-range restaurants, increasing customer satisfaction and engagement.A potential negative insight is that some high-cost restaurants have low ratings, which may affect their growth. However, this can be used constructively by identifying areas of improvement for such restaurants."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code(Most Popular Cuisines)\n",
        "\n",
        "# Split multiple cuisines into individual entries\n",
        "cuisine_series = final_df['Cuisines'].str.split(', ').explode()\n",
        "\n",
        "# Get top 10 cuisines\n",
        "top_cuisines = cuisine_series.value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=top_cuisines.values, y=top_cuisines.index)\n",
        "plt.title('Top 10 Most Popular Cuisines')\n",
        "plt.xlabel('Number of Restaurants')\n",
        "plt.ylabel('Cuisine')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart was chosen because it is the most effective way to compare the frequency of categorical variables. It clearly shows which cuisines are most commonly offered by restaurants."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that certain cuisines such as North Indian, Chinese, and Fast Food dominate the restaurant market. This indicates strong customer demand for these cuisines, while other cuisines are comparatively less common."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights can create a positive business impact by helping Zomato promote popular cuisines and guide new restaurants on which cuisines have higher demand.\n",
        "A possible negative insight is that less popular cuisines may struggle to gain visibility. However, this can be addressed by targeted promotions and recommendations to niche customer segments."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code(Distribution of Average Ratings)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(final_df['Avg_Rating'], bins=10, kde=True)\n",
        "plt.title('Distribution of Average Restaurant Ratings')\n",
        "plt.xlabel('Average Rating')\n",
        "plt.ylabel('Number of Restaurants')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram was chosen to understand the distribution of restaurant ratings. It helps identify how ratings are spread across restaurants and whether most restaurants receive low, average, or high ratings."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that most restaurants have average ratings between 3.0 and 4.5. Very few restaurants have extremely low or extremely high ratings. This indicates that the majority of restaurants provide a satisfactory customer experience."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, this insight helps Zomato understand overall customer satisfaction levels and identify high-performing restaurants for promotion.\n",
        "A possible negative insight is that restaurants with consistently low ratings may lose customers. However, identifying these restaurants allows targeted improvements and quality control measures to enhance customer experience."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code(Total Reviews vs Average Rating)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.scatterplot(data=final_df, x='Total_Reviews', y='Avg_Rating')\n",
        "plt.title('Total Reviews vs Average Rating')\n",
        "plt.xlabel('Total Number of Reviews')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scatter plot was chosen to analyze the relationship between the number of reviews and average rating. It helps understand whether popular restaurants  also maintain good customer satisfaction."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that restaurants with a high number of reviews generally maintain average to high ratings, indicating consistent customer satisfaction. Some restaurants with fewer reviews also have high ratings, suggesting they may be new or less discovered but high quality."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights help Zomato identify reliable and popular restaurants that can be promoted to customers. Restaurants with good ratings but fewer reviews can be highlighted to increase visibility.\n",
        "\n",
        "A negative insight is that restaurants with many reviews but lower ratings may face customer trust issues, which could impact growth. However, this insight allows early identification and improvement opportunities."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code(Distribution of Restaurant Cost)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(final_df['Cost'], bins=15, kde=True)\n",
        "plt.title('Distribution of Restaurant Cost')\n",
        "plt.xlabel('Cost for Two')\n",
        "plt.ylabel('Number of Restaurants')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram was chosen to understand how restaurant costs are distributed across the dataset. It helps identify common price ranges and the presence of low-cost or high-cost restaurants."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that most restaurants fall in the low to mid price range, while only a small number of restaurants are high-priced. This indicates that the platform is dominated by affordable and mid-range dining options."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, this insight helps Zomato understand customer affordability and focus on promoting restaurants that match popular price ranges.\n",
        "A possible negative insight is that premium restaurants form a smaller segment and may attract fewer customers. However, this can be addressed by targeted marketing to premium users."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code(Average Rating by Cuisine (Top Cuisines))\n",
        "\n",
        "# Split cuisines and explode\n",
        "cuisine_rating_df = final_df[['Cuisines', 'Avg_Rating']].copy()\n",
        "cuisine_rating_df['Cuisines'] = cuisine_rating_df['Cuisines'].str.split(', ')\n",
        "cuisine_rating_df = cuisine_rating_df.explode('Cuisines')\n",
        "\n",
        "# Calculate average rating per cuisine\n",
        "avg_rating_by_cuisine = (\n",
        "    cuisine_rating_df\n",
        "    .groupby('Cuisines')['Avg_Rating']\n",
        "    .mean()\n",
        "    .sort_values(ascending=False)\n",
        "    .head(10)\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=avg_rating_by_cuisine.values, y=avg_rating_by_cuisine.index)\n",
        "plt.title('Top 10 Cuisines by Average Rating')\n",
        "plt.xlabel('Average Rating')\n",
        "plt.ylabel('Cuisine')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart was chosen to compare the average customer ratings across different cuisines. It clearly highlights which cuisines are better rated and preferred by customers."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that some cuisines consistently receive higher average ratings compared to others. This indicates that customer satisfaction varies by cuisine type and certain cuisines are more positively received."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, these insights can help Zomato promote highly rated cuisines and guide restaurants on menu planning based on customer preferences.\n",
        "A possible negative insight is that cuisines with lower average ratings may receive less customer interest. However, this insight can be used to improve food quality, pricing, or service for those cuisines."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code(Average Rating by Cost Category)\n",
        "\n",
        "# Create cost categories\n",
        "final_df['Cost_Category'] = pd.cut(\n",
        "    final_df['Cost'],\n",
        "    bins=[0, 500, 1000, 2000, final_df['Cost'].max()],\n",
        "    labels=['Low', 'Mid', 'High', 'Premium']\n",
        ")\n",
        "\n",
        "# Calculate average rating per cost category\n",
        "avg_rating_by_cost = final_df.groupby('Cost_Category')['Avg_Rating'].mean().reset_index()\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.barplot(data=avg_rating_by_cost, x='Cost_Category', y='Avg_Rating')\n",
        "plt.title('Average Rating by Cost Category')\n",
        "plt.xlabel('Cost Category')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart was chosen to compare average customer ratings across different cost categories. It helps understand whether pricing segments influence customer satisfaction."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that mid-range and premium restaurants generally receive slightly higher average ratings compared to low-cost restaurants. However, the difference is not very large, indicating that good customer experience can be achieved at all price levels."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, this insight helps customers choose restaurants based on both budget and expected quality. For Zomato, it supports better segmentation and personalized recommendations across price ranges.\n",
        "A possible negative insight is that low-cost restaurants may receive slightly lower ratings on average. However, this can be improved through better service quality and targeted feedback mechanisms."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code(Distribution of Total Reviews)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(final_df['Total_Reviews'], bins=15, kde=True)\n",
        "plt.title('Distribution of Total Reviews per Restaurant')\n",
        "plt.xlabel('Total Number of Reviews')\n",
        "plt.ylabel('Number of Restaurants')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram was chosen to understand how customer engagement is distributed across restaurants. It helps identify whether most restaurants receive few reviews or if engagement is evenly spread."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that most restaurants have a relatively low to moderate number of reviews, while only a few restaurants receive a very high number of reviews. This indicates that customer engagement is concentrated around a limited set of popular restaurants."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, this insight helps Zomato identify highly popular restaurants for promotion and recognize less-reviewed restaurants that may need better visibility.\n",
        "A negative insight is that restaurants with very few reviews may struggle to gain customer trust. However, this can be addressed through onboarding support, promotions, and recommendation boosts."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code(Cuisine-wise Restaurant Count by Cost Category)\n",
        "\n",
        "# Prepare cuisine data\n",
        "cuisine_cost_df = final_df[['Cuisines', 'Cost_Category']].copy()\n",
        "cuisine_cost_df['Cuisines'] = cuisine_cost_df['Cuisines'].str.split(', ')\n",
        "cuisine_cost_df = cuisine_cost_df.explode('Cuisines')\n",
        "\n",
        "# Select top 5 cuisines for clarity\n",
        "top_cuisines = cuisine_cost_df['Cuisines'].value_counts().head(5).index\n",
        "filtered_df = cuisine_cost_df[cuisine_cost_df['Cuisines'].isin(top_cuisines)]\n",
        "\n",
        "plt.figure(figsize=(9,5))\n",
        "sns.countplot(data=filtered_df, x='Cuisines', hue='Cost_Category')\n",
        "plt.title('Cuisine-wise Restaurant Count by Cost Category')\n",
        "plt.xlabel('Cuisine')\n",
        "plt.ylabel('Number of Restaurants')\n",
        "plt.legend(title='Cost Category')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A count plot was chosen to compare how different cuisines are distributed across cost categories. It helps understand pricing patterns within popular cuisines."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that popular cuisines such as North Indian and Chinese are mostly concentrated in the low and mid cost categories, while fewer restaurants fall under the premium segment. This indicates that these cuisines are more accessible and cater to a wider audience."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This insight helps Zomato understand market positioning of cuisines and assists restaurant owners in pricing decisions.\n",
        "A possible negative insight is that premium segments for popular cuisines are limited, which may restrict options for high-end customers. However, this also highlights opportunities for expansion."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code(Cost vs Average Rating (Box Plot))\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.boxplot(data=final_df, x='Cost_Category', y='Avg_Rating')\n",
        "plt.title('Average Rating Distribution Across Cost Categories')\n",
        "plt.xlabel('Cost Category')\n",
        "plt.ylabel('Average Rating')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A box plot was chosen to compare the distribution of average ratings across different cost categories. It helps identify variation, median ratings, and the presence of outliers in each price segment."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that mid and premium cost categories generally have slightly higher median ratings, but there is significant overlap across all cost categories. This indicates that good customer ratings are not limited to expensive restaurants."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This insight helps customers make informed choices without assuming that higher cost always means better quality. For Zomato, it supports fair recommendations across all price ranges.\n",
        "A negative insight is that some premium restaurants show wide rating variation, which may impact customer trust. However, this can be addressed through quality monitoring and feedback-driven improvements"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code(Top Restaurants by Average Rating (with sufficient reviews))\n",
        "\n",
        "# Filter restaurants with at least 20 reviews for reliability\n",
        "top_restaurants = final_df[final_df['Total_Reviews'] >= 20]\n",
        "\n",
        "# Sort by average rating and take top 10\n",
        "top_restaurants = top_restaurants.sort_values(\n",
        "    by='Avg_Rating', ascending=False\n",
        ").head(10)\n",
        "\n",
        "plt.figure(figsize=(9,5))\n",
        "sns.barplot(\n",
        "    x=top_restaurants['Avg_Rating'],\n",
        "    y=top_restaurants['Name']\n",
        ")\n",
        "plt.title('Top 10 Restaurants by Average Rating (Min 20 Reviews)')\n",
        "plt.xlabel('Average Rating')\n",
        "plt.ylabel('Restaurant Name')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart was chosen to clearly compare average ratings of top-performing restaurants. A minimum review threshold was applied to ensure ratings are reliable and not biased by very few reviews."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart highlights restaurants that consistently receive high ratings along with sufficient customer engagement. These restaurants represent high quality and strong customer trust."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This insight helps Zomato identify top-performing restaurants for recommendations and promotions. It also helps customers make confident dining choices based on trusted ratings.\n",
        "\n",
        "A possible negative insight is that restaurants with fewer reviews may not appear in this list despite good quality. However, this can be addressed through visibility boosts for new restaurants."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code(Low Rated Restaurants (Average Rating < 3))\n",
        "\n",
        "\n",
        "# Filter low-rated restaurants\n",
        "low_rated_restaurants = final_df[final_df['Avg_Rating'] < 3]\n",
        "\n",
        "# Take top 10 lowest-rated restaurants\n",
        "low_rated_restaurants = low_rated_restaurants.sort_values(\n",
        "    by='Avg_Rating'\n",
        ").head(10)\n",
        "\n",
        "plt.figure(figsize=(9,5))\n",
        "sns.barplot(\n",
        "    x=low_rated_restaurants['Avg_Rating'],\n",
        "    y=low_rated_restaurants['Name']\n",
        ")\n",
        "plt.title('Top 10 Lowest Rated Restaurants')\n",
        "plt.xlabel('Average Rating')\n",
        "plt.ylabel('Restaurant Name')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart was chosen to clearly identify restaurants with consistently low ratings. This helps in detecting problem areas where customer satisfaction is poor."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart highlights restaurants that receive consistently low customer ratings, indicating dissatisfaction related to food quality, service, or pricing. These restaurants require immediate attention."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This insight helps Zomato identify underperforming restaurants and work with them to improve service quality, menu offerings, or customer experience.\n",
        "A negative insight is that consistently low-rated restaurants may damage platform reputation if not addressed, but early identification allows corrective action."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code( Cost vs Total Reviews)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.scatterplot(data=final_df, x='Cost', y='Total_Reviews')\n",
        "plt.title('Cost vs Total Number of Reviews')\n",
        "plt.xlabel('Cost for Two')\n",
        "plt.ylabel('Total Number of Reviews')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A scatter plot was chosen to understand the relationship between restaurant pricing and customer engagement. It helps analyze whether higher or lower priced restaurants attract more reviews."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that most restaurants with a high number of reviews fall in the low to mid cost range. Expensive restaurants generally receive fewer reviews, indicating lower customer volume compared to affordable options."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This insight helps Zomato understand that affordable restaurants drive higher customer engagement and should be prioritized in recommendations.\n",
        "A negative insight is that premium restaurants attract fewer customers, which may limit their visibility. However, this opens opportunities for targeted marketing toward premium users."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code(Correlation Heatmap)\n",
        "\n",
        "# Selecting numerical columns\n",
        "corr_data = final_df[['Cost', 'Avg_Rating', 'Total_Reviews']]\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.heatmap(\n",
        "    corr_data.corr(),\n",
        "    annot=True,\n",
        "    cmap='coolwarm',\n",
        "    fmt='.2f'\n",
        ")\n",
        "plt.title('Correlation Heatmap of Numerical Features')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A correlation heatmap was chosen to understand the strength and direction of relationships between numerical variables such as cost, average rating, and total reviews. It provides a summarized view of how features are related to each other."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The heatmap shows a weak correlation between cost and average rating, indicating that higher pricing does not strongly influence customer satisfaction. The relationship between total reviews and average rating is also weak to moderate, suggesting that popularity does not always result in higher ratings."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "\n",
        "sns.pairplot(\n",
        "    final_df[['Cost', 'Avg_Rating', 'Total_Reviews']],\n",
        "    diag_kind='kde'\n",
        ")\n",
        "plt.suptitle('Pair Plot of Cost, Average Rating, and Total Reviews', y=1.02)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pair plot was chosen to visualize pairwise relationships between multiple numerical variables simultaneously. It helps in identifying trends, correlations, and distributions in a single consolidated view."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pair plot shows no strong linear relationship between cost, average rating, and total reviews. It also highlights the distribution of each variable and confirms the weak correlations observed earlier in the correlation heatmap."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis 1:\n",
        "There is no significant relationship between restaurant cost and average customer rating.\n",
        "\n",
        "Hypothesis 2:\n",
        "Restaurants with higher cost categories do not have significantly higher average ratings than low-cost restaurants.\n",
        "\n",
        "Hypothesis 3:\n",
        "There is no significant relationship between the total number of reviews and the average rating of a restaurant."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H):\n",
        "There is no significant relationship between restaurant cost and average customer rating.\n",
        "\n",
        "Alternate Hypothesis (H):\n",
        "There is a significant relationship between restaurant cost and average customer rating."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Pearson Correlation Test: Cost vs Average Rating\n",
        "correlation, p_value = pearsonr(final_df['Cost'], final_df['Avg_Rating'])\n",
        "\n",
        "print(\"Correlation Coefficient:\", correlation)\n",
        "print(\"P-value:\", p_value)\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson Correlation Test was used to obtain the p-value."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson Correlation Test was chosen because both variables, cost and average rating, are numerical and continuous. This test helps measure the strength and direction of the linear relationship between two continuous variables and determines whether the relationship is statistically significant."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H):\n",
        "There is no significant difference in average ratings between low-cost and high-cost restaurants.\n",
        "\n",
        "Alternate Hypothesis (H):\n",
        "There is a significant difference in average ratings between low-cost and high-cost restaurants."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Selecting ratings for low-cost and premium restaurants\n",
        "low_cost_ratings = final_df[final_df['Cost_Category'] == 'Low']['Avg_Rating']\n",
        "high_cost_ratings = final_df[final_df['Cost_Category'] == 'Premium']['Avg_Rating']\n",
        "\n",
        "# Independent T-Test\n",
        "t_statistic, p_value = ttest_ind(\n",
        "    low_cost_ratings,\n",
        "    high_cost_ratings,\n",
        "    nan_policy='omit'\n",
        ")\n",
        "\n",
        "print(\"T-statistic:\", t_statistic)\n",
        "print(\"P-value:\", p_value)\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Independent Two-Sample T-Test was used to obtain the p-value."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Independent Two-Sample T-Test was chosen because the goal was to compare the mean average ratings of two independent groups (low-cost and high-cost restaurants). This test is appropriate when comparing the means of two unrelated samples."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H):\n",
        "There is no significant relationship between the total number of reviews and the average rating of a restaurant.\n",
        "\n",
        "Alternate Hypothesis (H):\n",
        "There is a significant relationship between the total number of reviews and the average rating of a restaurant."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Pearson Correlation Test: Total Reviews vs Average Rating\n",
        "correlation, p_value = pearsonr(\n",
        "    final_df['Total_Reviews'],\n",
        "    final_df['Avg_Rating']\n",
        ")\n",
        "\n",
        "print(\"Correlation Coefficient:\", correlation)\n",
        "print(\"P-value:\", p_value)\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson Correlation Test was used to obtain the p-value."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson Correlation Test was chosen because both the total number of reviews and average rating are numerical variables. This test helps determine the strength and significance of the linear relationship between two continuous variables."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "final_df.isnull().sum()\n",
        "\n",
        "# Imputing missing values (if any remain)\n",
        "final_df['Avg_Rating'] = final_df['Avg_Rating'].fillna(final_df['Avg_Rating'].median())\n",
        "final_df['Total_Reviews'] = final_df['Total_Reviews'].fillna(0)\n",
        "final_df['Cost'] = final_df['Cost'].fillna(final_df['Cost'].median())\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing values in numerical columns were handled using median imputation for variables such as cost and average rating, as the median is robust to outliers. Missing values in the total number of reviews were filled with zero to represent restaurants with no customer reviews. These techniques ensure that no important data is lost while making the dataset suitable for machine learning models."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# IQR Method\n",
        "\n",
        "def remove_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "# Removing outliers from Cost and Total_Reviews\n",
        "final_df = remove_outliers_iqr(final_df, 'Cost')\n",
        "final_df = remove_outliers_iqr(final_df, 'Total_Reviews')\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outliers were handled using the Interquartile Range (IQR) method for numerical variables such as cost and total reviews. This method helps remove extreme values without affecting the overall distribution of the data. It was chosen because it is robust, easy to interpret, and suitable for skewed real-world data like restaurant pricing and review counts."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "\n",
        "# 1. Label Encoding for Cost_Category (Ordinal feature)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "final_df['Cost_Category_Encoded'] = label_encoder.fit_transform(final_df['Cost_Category'])\n",
        "\n",
        "# 2. One-Hot Encoding for Cuisines (Top cuisines only to avoid high dimensionality)\n",
        "\n",
        "# Get top 5 cuisines\n",
        "top_cuisines = (\n",
        "    final_df['Cuisines']\n",
        "    .str.split(', ')\n",
        "    .explode()\n",
        "    .value_counts()\n",
        "    .head(5)\n",
        "    .index\n",
        ")\n",
        "\n",
        "# Create binary columns for top cuisines\n",
        "for cuisine in top_cuisines:\n",
        "    final_df[f'Cuisine_{cuisine}'] = final_df['Cuisines'].apply(\n",
        "        lambda x: 1 if cuisine in x else 0\n",
        "    )\n",
        "\n",
        "# Display encoded columns\n",
        "final_df.head()\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Encoding was used for the Cost_Category variable because it represents an ordinal relationship between categories such as Low, Mid, High, and Premium. This preserves the natural order of pricing levels.\n",
        "\n",
        "One-Hot Encoding was applied to the most frequent cuisines to convert categorical cuisine information into binary numerical features. Only top cuisines were encoded to avoid high dimensionality. These encoding techniques make the data suitable for distance-based clustering algorithms like K-Means."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contractions\n",
        "\n",
        "!pip install contractions\n",
        "import contractions\n",
        "\n",
        "review_df['Clean_Review'] = review_df['Review'].apply(\n",
        "    lambda x: contractions.fix(str(x))\n",
        ")"
      ],
      "metadata": {
        "id": "atOYgzdFBUWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "\n",
        "review_df['Clean_Review'] = review_df['Clean_Review'].str.lower()\n"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "\n",
        "import string\n",
        "\n",
        "review_df['Clean_Review'] = review_df['Clean_Review'].apply(\n",
        "    lambda x: x.translate(str.maketrans('', '', string.punctuation))\n",
        ")\n"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "\n",
        "import re\n",
        "\n",
        "review_df['Clean_Review'] = review_df['Clean_Review'].apply(\n",
        "    lambda x: re.sub(r'http\\S+|www\\S+|https\\S+', '', x)\n",
        ")\n",
        "\n",
        "review_df['Clean_Review'] = review_df['Clean_Review'].apply(\n",
        "    lambda x: re.sub(r'\\w*\\d\\w*', '', x)\n",
        ")\n"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "review_df['Clean_Review'] = review_df['Clean_Review'].apply(\n",
        "    lambda x: ' '.join([word for word in x.split() if word not in stop_words])\n",
        ")\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces\n",
        "\n",
        "review_df['Clean_Review'] = review_df['Clean_Review'].apply(\n",
        "    lambda x: re.sub(r'\\s+', ' ', x).strip()\n",
        ")\n"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text\n",
        "\n",
        "review_df['Rephrased_Review'] = review_df['Clean_Review']\n"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "review_df['Tokens'] = review_df['Rephrased_Review'].apply(\n",
        "    lambda x: word_tokenize(x)\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "review_df['Normalized_Tokens'] = review_df['Tokens'].apply(\n",
        "    lambda tokens: [lemmatizer.lemmatize(word) for word in tokens]\n",
        ")\n"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization was used for text normalization because it converts words to their meaningful base form while preserving context. Unlike stemming, lemmatization produces valid words, making it more suitable for sentiment analysis and text clustering."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging\n",
        "\n",
        "from nltk import pos_tag\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "review_df['POS_Tags'] = review_df['Tokens'].apply(\n",
        "    lambda tokens: pos_tag(tokens)\n",
        ")\n"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorising Text\n",
        "# TF-IDF\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Join tokens back into sentences\n",
        "review_df['Final_Text'] = review_df['Tokens'].apply(\n",
        "    lambda tokens: ' '.join(tokens)\n",
        ")\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=500)\n",
        "\n",
        "tfidf_matrix = tfidf.fit_transform(review_df['Final_Text'])\n",
        "\n",
        "tfidf_matrix.shape\n"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF (Term FrequencyInverse Document Frequency) vectorization was used to convert textual reviews into numerical form. TF-IDF assigns higher importance to meaningful and less frequent words while reducing the impact of commonly occurring words. This makes it suitable for text clustering and sentiment analysis tasks."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "# Log transform Total_Reviews to reduce skewness\n",
        "final_df['Log_Total_Reviews'] = np.log1p(final_df['Total_Reviews'])\n",
        "\n",
        "# Create Rating per Cost feature (value for money indicator)\n",
        "final_df['Rating_per_Cost'] = final_df['Avg_Rating'] / (final_df['Cost'] + 1)\n",
        "\n",
        "# Drop original Total_Reviews to reduce correlation\n",
        "final_df = final_df.drop(columns=['Total_Reviews'])\n",
        "\n",
        "final_df[['Log_Total_Reviews', 'Rating_per_Cost']].head()\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "selected_features = [\n",
        "    'Cost',\n",
        "    'Avg_Rating',\n",
        "    'Log_Total_Reviews',\n",
        "    'Rating_per_Cost',\n",
        "    'Cost_Category_Encoded'\n",
        "]\n",
        "\n",
        "# Include cuisine one-hot encoded features\n",
        "cuisine_features = [col for col in final_df.columns if col.startswith('Cuisine_')]\n",
        "selected_features.extend(cuisine_features)\n",
        "\n",
        "X = final_df[selected_features]\n",
        "X.head()\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection was performed using domain knowledge and correlation analysis. Highly correlated and less informative features were removed, while features that capture pricing, customer satisfaction, popularity, and cuisine preference were retained. This helps reduce noise, avoid overfitting, and improve clustering performance."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cost, average rating, and log-transformed review count were found to be important as they represent pricing, customer satisfaction, and popularity. The value-for-money feature captures combined customer perception, while encoded cuisine features help distinguish restaurants based on food preference patterns."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, data transformation was required because features were on different scales. Standardization was applied using StandardScaler to ensure that all features contribute equally to distance-based clustering algorithms like K-Means. This prevents features with larger values from dominating the clustering process."
      ],
      "metadata": {
        "id": "Qg2DRhO4EX_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_transformed = scaler.fit_transform(X)\n",
        "\n",
        "X_transformed.shape\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_scaled.shape\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "StandardScaler was used to scale the data because it standardizes features to have zero mean and unit variance. This is important for distance-based algorithms like K-Means, as it ensures that features such as cost and ratings contribute equally to clustering."
      ],
      "metadata": {
        "id": "HGF2gZX-Ezq-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, dimensionality reduction is useful because the dataset contains multiple numerical and encoded features, which can increase computational complexity and make visualization difficult. Reducing dimensions helps retain important information while simplifying the feature space."
      ],
      "metadata": {
        "id": "hteMb02GE1Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "# PCA\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "X_pca.shape\n"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Principal Component Analysis (PCA) was used for dimensionality reduction because it transforms the data into a lower-dimensional space while preserving maximum variance. PCA also helps in visualizing clusters effectively."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test = train_test_split(\n",
        "    X_scaled, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An 80:20 data splitting ratio was used, where 80% of the data is used for training and 20% for testing. This ratio provides sufficient data for model learning while reserving a portion for evaluation. Although clustering is unsupervised, splitting helps in validating model stability."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imbalanced data typically refers to unequal class distribution in supervised learning problems. Since this project uses unsupervised learning (K-Means clustering) and does not have predefined target labels, class imbalance is not directly applicable. Therefore, the dataset is not considered imbalanced in the traditional sense."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No imbalance handling technique was applied because the problem is unsupervised and does not involve class labels. Clustering algorithms naturally group data based on feature similarity rather than class distribution."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "# ML Model - 1 Implementation (K-Means Clustering)\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Initialize K-Means\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "kmeans.fit(X_scaled)\n",
        "\n",
        "# Predict clusters\n",
        "cluster_labels = kmeans.predict(X_scaled)\n",
        "\n",
        "# Add clusters to dataframe\n",
        "final_df['Cluster'] = cluster_labels\n",
        "\n",
        "final_df[['Name', 'Cluster']].head()\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Silhouette Score\n",
        "\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sil_score = silhouette_score(X_scaled, cluster_labels)\n",
        "\n",
        "# Plotting Silhouette Score\n",
        "plt.bar(['K-Means'], [sil_score])\n",
        "plt.title('Silhouette Score for K-Means Clustering')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.show()\n",
        "\n",
        "sil_score\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "# Hyperparameter Tuning using Elbow Method\n",
        "\n",
        "wcss = []\n",
        "\n",
        "for k in range(2, 8):\n",
        "    km = KMeans(n_clusters=k, random_state=42)\n",
        "    km.fit(X_scaled)\n",
        "    wcss.append(km.inertia_)\n",
        "\n",
        "plt.plot(range(2, 8), wcss, marker='o')\n",
        "plt.xlabel('Number of Clusters (K)')\n",
        "plt.ylabel('WCSS')\n",
        "plt.title('Elbow Method for Hyperparameter Tuning')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Elbow Method was used for hyperparameter tuning to determine the optimal number of clusters. It helps identify the value of K where adding more clusters does not significantly reduce the within-cluster sum of squares."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, after selecting the optimal number of clusters using the Elbow Method, the clustering quality improved. This was reflected by a better Silhouette Score and more clearly separated clusters, indicating improved model performance."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation (DBSCAN)\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "dbscan = DBSCAN(eps=0.8, min_samples=5)\n",
        "\n",
        "dbscan_labels = dbscan.fit_predict(X_scaled)\n",
        "\n",
        "final_df['DBSCAN_Cluster'] = dbscan_labels\n",
        "\n",
        "final_df[['Name', 'DBSCAN_Cluster']].head()\n"
      ],
      "metadata": {
        "id": "Xm9_WsW8H_Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Remove noise points (-1)\n",
        "mask = dbscan_labels != -1\n",
        "\n",
        "if len(set(dbscan_labels[mask])) > 1:\n",
        "    dbscan_sil_score = silhouette_score(X_scaled[mask], dbscan_labels[mask])\n",
        "else:\n",
        "    dbscan_sil_score = -1\n",
        "\n",
        "# Plot\n",
        "plt.bar(['DBSCAN'], [dbscan_sil_score])\n",
        "plt.title('Silhouette Score for DBSCAN')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.show()\n",
        "\n",
        "dbscan_sil_score\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "# Hyperparameter tuning for DBSCAN (eps exploration)\n",
        "\n",
        "eps_values = [0.5, 0.7, 0.9, 1.1]\n",
        "scores = []\n",
        "\n",
        "for eps in eps_values:\n",
        "    db = DBSCAN(eps=eps, min_samples=5)\n",
        "    labels = db.fit_predict(X_scaled)\n",
        "    mask = labels != -1\n",
        "\n",
        "    if len(set(labels[mask])) > 1:\n",
        "        score = silhouette_score(X_scaled[mask], labels[mask])\n",
        "    else:\n",
        "        score = -1\n",
        "\n",
        "    scores.append(score)\n",
        "\n",
        "plt.plot(eps_values, scores, marker='o')\n",
        "plt.xlabel('EPS value')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('DBSCAN Hyperparameter Tuning')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual hyperparameter tuning was performed by experimenting with different epsilon (eps) values. DBSCAN is sensitive to eps, and tuning helps identify the value that produces well-separated clusters while minimizing noise."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DBSCAN showed improvement in identifying noise and outliers compared to K-Means. While the Silhouette Score may be lower in some cases, DBSCAN provides better real-world segmentation by excluding anomalous restaurants that do not belong to any cluster."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Silhouette Score indicates how well restaurants are grouped within clusters and how distinct each cluster is. A higher score suggests clear segmentation, which helps businesses design targeted marketing strategies. DBSCANs ability to identify noise helps businesses detect unusual or underperforming restaurants, enabling focused improvement or risk mitigation strategies."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "# ML Model - 3 Implementation (Agglomerative Clustering)\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "agglo = AgglomerativeClustering(n_clusters=3, linkage='ward')\n",
        "\n",
        "agglo_labels = agglo.fit_predict(X_scaled)\n",
        "\n",
        "final_df['Agglomerative_Cluster'] = agglo_labels\n",
        "\n",
        "final_df[['Name', 'Agglomerative_Cluster']].head()\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "agglo_sil_score = silhouette_score(X_scaled, agglo_labels)\n",
        "\n",
        "plt.bar(['Agglomerative'], [agglo_sil_score])\n",
        "plt.title('Silhouette Score for Agglomerative Clustering')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.show()\n",
        "\n",
        "agglo_sil_score\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "# Hyperparameter tuning for Agglomerative Clustering\n",
        "\n",
        "linkages = ['ward', 'complete', 'average']\n",
        "scores = []\n",
        "\n",
        "for link in linkages:\n",
        "    model = AgglomerativeClustering(n_clusters=3, linkage=link)\n",
        "    labels = model.fit_predict(X_scaled)\n",
        "    score = silhouette_score(X_scaled, labels)\n",
        "    scores.append(score)\n",
        "\n",
        "plt.bar(linkages, scores)\n",
        "plt.xlabel('Linkage Method')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Agglomerative Clustering Hyperparameter Tuning')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manual hyperparameter tuning was performed by experimenting with different linkage methods. Linkage selection impacts how clusters are formed, and testing multiple options helps identify the one that produces better cluster separation."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agglomerative clustering provided stable and interpretable clusters. While the silhouette score was comparable to K-Means, the hierarchical nature of the model helped better understand relationships between restaurant groups."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Silhouette Score was considered as the primary evaluation metric because it measures how well restaurants are grouped within clusters and how clearly different clusters are separated. A higher Silhouette Score indicates meaningful segmentation, which helps businesses design targeted marketing strategies, pricing plans, and customer engagement approaches."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means clustering was chosen as the final model because it provided well-defined clusters, a comparatively higher Silhouette Score, and stable performance. It is computationally efficient, easy to interpret, and suitable for large-scale business applications such as restaurant segmentation and recommendation systems."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The K-Means model was explained using cluster centroid analysis. Cluster centroids represent the average value of each feature within a cluster, indicating the relative importance of features in defining each group. Features such as cost, average rating, review popularity, and cuisine indicators played a major role in differentiating restaurant clusters, helping businesses understand customer preferences and market segments."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "\n",
        "\n",
        "import joblib\n",
        "\n",
        "joblib.dump(kmeans, 'kmeans_restaurant_clustering_model.joblib')\n"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "\n",
        "loaded_model = joblib.load('kmeans_restaurant_clustering_model.joblib')\n",
        "\n",
        "# Predict clusters for unseen/test data\n",
        "sample_predictions = loaded_model.predict(X_scaled[:5])\n",
        "\n",
        "sample_predictions\n"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, a complete end-to-end machine learning pipeline was developed to analyze and cluster restaurants based on pricing, customer ratings, popularity, and cuisine preferences. Multiple clustering models including K-Means, DBSCAN, and Agglomerative Clustering were implemented and evaluated using Silhouette Score. K-Means was selected as the final model due to its stability, interpretability, and better clustering performance. The results provide meaningful business insights that can support targeted marketing, customer segmentation, and strategic decision-making. The model is deployment-ready and can be extended further with real-time data and recommendation systems."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}